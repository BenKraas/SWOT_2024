{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "\n",
    "# Third-party library imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import contextily as ctx\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "import earthaccess\n",
    "\n",
    "# Matplotlib inline magic command\n",
    "%matplotlib inline\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = {\n",
    "    \"classification\": {\n",
    "        \"type\": int,\n",
    "        \"null_value\": 255,\n",
    "        \"description\": \"Flags indicating water detection results.\",\n",
    "    },\n",
    "    \"classification_str\": {\n",
    "        \"type\": str,\n",
    "        \"null_value\": \"unknown\",\n",
    "        \"value_map\": {\n",
    "            1: \"land\",\n",
    "            2: \"land_near_water \",\n",
    "            3: \"water_near_land \",\n",
    "            4: \"open_water \",\n",
    "            5: \"dark_water  \",\n",
    "            6: \"low_coh_water_near_land  \",\n",
    "            7: \"open_low_coh_water \"\n",
    "        },\n",
    "        \"description\": \"Flags indicating water detection results as string.\",\n",
    "    },\n",
    "    \"layover_impact\": {\n",
    "        \"type\": float,\n",
    "        \"null_value\": 9.969209968386869e+36,\n",
    "        \"description\": \"Estimate of the height error caused by layover, which may not be reliable on a pixel by pixel basis, but may be useful to augment aggregated height uncertainties. \",\n",
    "    },\n",
    "    \"height\": {\n",
    "        \"type\": float,\n",
    "        \"null_value\": 9.96921e+36,\n",
    "        \"description\": \"Height of the pixel above the reference ellipsoid.\",\n",
    "    },\n",
    "    \"illumination_time\": {\n",
    "        \"type\": datetime,\n",
    "        \"null_value\": 9.969209968386869e+36,\n",
    "        \"description\": \"Time of measurement in seconds in the UTC time scale since 1 Jan 2000 00:00:00 UTC. [tai_utc_difference] is the difference between TAI and UTC reference time (seconds) for the first measurement of the data set. If a leap second occurs within the data set, the attribute leap_second is set to the UTC time at which the leap second occurs. \",\n",
    "    },\n",
    "\t\"geolocation_qual\": {\n",
    "        \"type\": int,\n",
    "        \"null_value\": 4294967295,\n",
    "        \"description\": \"Quality flag for the geolocation quantities in the pixel cloud data\",\n",
    "\t\t\"flag_masks\": {\n",
    "            \"layover_significant\": 1,\n",
    "            \"phase_noise_suspect\": 2,\n",
    "            \"phase_unwrapping_suspect\": 4,\n",
    "            \"model_dry_tropo_cor_suspect\": 8,\n",
    "            \"model_wet_tropo_cor_suspect\": 16,\n",
    "            \"iono_cor_gim_ka_suspect\": 32,\n",
    "            \"xovercal_suspect\": 64,\n",
    "            \"suspect_karin_telem\": 1024,\n",
    "            \"medium_phase_suspect\": 4096,\n",
    "            \"tvp_suspect\": 8192,\n",
    "            \"sc_event_suspect\": 16384,\n",
    "            \"small_karin_gap\": 32768,\n",
    "            \"specular_ringing_degraded\": 524288,\n",
    "            \"model_dry_tropo_cor_missing\": 1048576,\n",
    "            \"model_wet_tropo_cor_missing\": 2097152,\n",
    "            \"iono_cor_gim_ka_missing\": 4194304,\n",
    "            \"xovercal_missing\": 8388608,\n",
    "            \"geolocation_is_from_refloc\": 16777216,\n",
    "            \"no_geolocation_bad\": 33554432,\n",
    "            \"medium_phase_bad\": 67108864,\n",
    "            \"tvp_bad\": 134217728,\n",
    "            \"sc_event_bad\": 268435456,\n",
    "            \"large_karin_gap\": 536870912\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_010_318_155L_20240205T083356_20240205T083407_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (2764726/4434973) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_010_318_156L_20240205T083406_20240205T083417_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (2730960/6563603) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_012_154R_20240215T065603_20240215T065614_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (1959/3277260) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_012_155R_20240215T065613_20240215T065624_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (80015/4178722) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_012_156R_20240215T065623_20240215T065634_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (0/5045524) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_165_153R_20240220T180721_20240220T180732_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (564857/5879917) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_165_154L_20240220T180731_20240220T180742_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (1249763/3129797) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_165_154R_20240220T180731_20240220T180742_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (961991/4801288) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_318_155L_20240226T051901_20240226T051912_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (2958717/4595943) entries (Spatial filtering).\n",
      "[INFO] Found file: data\\Water mask pixel cloud\\SWOT_L2_HR_PIXC_011_318_156L_20240226T051911_20240226T051922_PIC0_01.nc\n",
      "[INFO] Column classification_str not found in dataset.\n",
      "Dataset contains (2755741/6881122) entries (Spatial filtering).\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify and open the first NetCDF file in the pixel cloud directory\n",
    "pixel_cloud_dir = Path(config['water_mask_pixel_cloud_dir'])\n",
    "file_list = list(pixel_cloud_dir.glob('*.nc'))\n",
    "filepath = file_list[0]  # Take the first file found\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for filepath in file_list:\n",
    "    try:\n",
    "        print(f\"[INFO] Found file: {filepath}\")\n",
    "\n",
    "        # 2. Load the pixel_cloud dataset and select the last 10,000 entries into a polars DataFrame\n",
    "        ds = xr.open_dataset(filepath, group='pixel_cloud')\n",
    "\n",
    "        # 3. Load the bounding box from a GeoJSON file as a GeoDataFrame\n",
    "        bbox_path = Path(config['data_dir']) / 'bbox.geojson'\n",
    "        with open(bbox_path, 'r') as f:\n",
    "            bbox_data = json.load(f)\n",
    "        bbox_gdf = gpd.GeoDataFrame.from_features(bbox_data['features'])\n",
    "\n",
    "        # keep only the columns we are interested in\n",
    "        data_columns_selection = list(data_columns.keys())\n",
    "        for column in data_columns_selection:\n",
    "            if column not in ds.variables:\n",
    "                print(f\"[INFO] Column {column} not found in dataset.\")\n",
    "                data_columns_selection.remove(column)\n",
    "        df = ds[data_columns_selection].to_dataframe()\n",
    "        full_len = len(df)\n",
    "\n",
    "        # keep only lat and lon in the bbox\n",
    "        df = df[(df['latitude'] >= bbox_gdf.bounds.miny[0]) & (df['latitude'] <= bbox_gdf.bounds.maxy[0])]\n",
    "        df = df[(df['longitude'] >= bbox_gdf.bounds.minx[0]) & (df['longitude'] <= bbox_gdf.bounds.maxx[0])]\n",
    "        print(f\"Dataset contains ({len(df)}/{full_len}) entries (Spatial filtering).\")\n",
    "\n",
    "        # create a new column with the classification as string\n",
    "        df['classification_str'] = df['classification'].replace(data_columns['classification_str']['value_map'])\n",
    "\n",
    "        # concatenate the dataframes\n",
    "        final_df = pd.concat([final_df, pd.DataFrame(df)])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e} - Skipping file {filepath}\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains (15661/14068729) entries after filtering.\n"
     ]
    }
   ],
   "source": [
    "# Filtering the dataset\n",
    "pre_filter_len = len(final_df)\n",
    "\n",
    "# only keep the rows where classification is not 1 (land)\n",
    "final_df = final_df[final_df['classification'] == 4] # 4 is open water\n",
    "# final_df = final_df[final_df['geolocation_qual'] < 4] # Value is taken from an example notebook by NASA (https://github.com/podaac/tutorials/blob/master/notebooks/datasets/SWOT_PIXC_PhaseUnwrap_localmachine.ipynb)\n",
    "\n",
    "# Filter for SNR flag (Product Description P.13)\n",
    "# measurements are only useful where the SNR is sufficiently high. The L2_HR_PIXC product is designed such that no KaRIn measurements are left out of the product simply because they fall outside of granule cross-track boundaries. However, data samples that are not reliable (e.g., due to insufficient SNR) are flagged.\n",
    "# Pending implementation, may be already resolved with the geolocation_qual flag\n",
    "\n",
    "print(f\"Dataset contains ({len(final_df)}/{pre_filter_len}) entries after filtering.\")\n",
    "df = final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification               float32\n",
      "layover_impact               float32\n",
      "height                       float32\n",
      "illumination_time     datetime64[ns]\n",
      "geolocation_qual             float64\n",
      "latitude                     float64\n",
      "longitude                    float64\n",
      "classification_str            object\n",
      "geometry                    geometry\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kasto\\AppData\\Local\\Temp\\ipykernel_53976\\575011049.py:19: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(output_file_name, driver='ESRI Shapefile')\n",
      "c:\\Users\\Kasto\\.conda\\envs\\SWOT_2024_2\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'classification' to 'classifica'\n",
      "  ogr_write(\n",
      "c:\\Users\\Kasto\\.conda\\envs\\SWOT_2024_2\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'layover_impact' to 'layover_im'\n",
      "  ogr_write(\n",
      "c:\\Users\\Kasto\\.conda\\envs\\SWOT_2024_2\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'illumination_time' to 'illuminati'\n",
      "  ogr_write(\n",
      "c:\\Users\\Kasto\\.conda\\envs\\SWOT_2024_2\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Field illuminati create as date field, though DateTime requested.\n",
      "  ogr_write(\n",
      "c:\\Users\\Kasto\\.conda\\envs\\SWOT_2024_2\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'geolocation_qual' to 'geolocatio'\n",
      "  ogr_write(\n",
      "c:\\Users\\Kasto\\.conda\\envs\\SWOT_2024_2\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'classification_str' to 'classifi_1'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "# convert to geodataframe\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "# print all gdf types\n",
    "print(gdf.dtypes)\n",
    "\n",
    "# Save the GeoDataFrame to a shapefile\n",
    "output_dir = Path(config['output_dir'])\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "output_file_name = output_dir / f'water_mask_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "\n",
    "# sloppy fix for index64 pandas issue\n",
    "gdf[\"row_id\"] = gdf.index + 1\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "gdf.set_index(\"row_id\", inplace = True)\n",
    "\n",
    "# save to shp\n",
    "gdf.to_file(output_file_name, driver='ESRI Shapefile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWOT_2024_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
